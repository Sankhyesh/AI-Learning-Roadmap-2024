[
  {
    "front": "What is LangChain?",
    "back": "An open-source framework designed for developing applications powered by Large Language Models (LLMs).",
    "type": "basic",
    "tags": ["LangChain", "LLM", "Framework", "CoreConcept"],
    "id": "uuid-v4-placeholder-1"
  },
  {
    "front": "What is the primary function of LangChain?",
    "back": "To simplify the creation of LLM-based applications.",
    "type": "basic",
    "tags": ["LangChain", "LLM", "Framework", "CoreConcept"],
    "id": "uuid-v4-placeholder-2"
  },
  {
    "front": "In the PDF chat app example, {{c1::Semantic Search}} is preferred over keyword search because it aims to understand the _meaning_ of the query and find text that is semantically similar.",
    "back": "Semantic Search",
    "type": "cloze",
    "tags": ["LangChain", "LLM", "SystemDesign", "SemanticSearch", "PDFChatApp"],
    "cloze_back_extra": "In the PDF chat app example, Semantic Search is preferred over keyword search because it aims to understand the _meaning_ of the query and find text that is semantically similar, leading to more contextually relevant results.",
    "id": "uuid-v4-placeholder-3"
  },
  {
    "front": "In the system design of an LLM-powered application, what are the two main capabilities of its \"Brain\" component?",
    "back": "1. Natural Language Understanding (NLU). 2. Context-Aware Text Generation.",
    "type": "basic",
    "tags": ["LangChain", "LLM", "SystemDesign", "NLU", "TextGeneration"],
    "mnemonic": "The Brain **UNC**overs text: **U**nderstanding **N**atural language, **C**ontextual Generation.",
    "id": "uuid-v4-placeholder-4"
  },
  {
    "front": "Semantic search works by converting text into {{c1::embeddings}} (vector representations that capture the semantic meaning of the text).",
    "back": "embeddings",
    "type": "cloze",
    "tags": ["LangChain", "LLM", "SemanticSearch", "Embeddings", "NLP"],
    "examples": "Techniques like Word2Vec, Doc2Vec, or BERT embeddings can be used.",
    "cloze_back_extra": "Semantic search works by converting text into embeddings (vector representations that capture the semantic meaning of the text).",
    "id": "uuid-v4-placeholder-5"
  },
  {
    "front": "In semantic search, after converting the user's query into a vector, what is the immediate next step?",
    "back": "The system calculates the similarity (e.g., cosine similarity or Euclidean distance) between the query vector and all document vectors.",
    "type": "basic",
    "tags": ["LangChain", "LLM", "SemanticSearch", "Embeddings", "VectorSimilarity"],
    "id": "uuid-v4-placeholder-6"
  },
  {
    "front": "What is a core concept in LangChain, giving the framework its name, that allows developers to sequence calls to LLMs or other utilities?",
    "back": "Chains.",
    "type": "basic",
    "tags": ["LangChain", "CoreConcept", "Chains", "Workflow"],
    "examples": "The output of one component in a chain automatically becomes the input for the next.",
    "mnemonic": "Lang**Chain** links steps together.",
    "id": "uuid-v4-placeholder-15"
  },
  {
    "front": "What does \"model-agnostic development\" mean in the context of LangChain?",
    "back": "It allows for easy switching between different LLM providers (e.g., OpenAI, Google) or models with minimal code changes.",
    "type": "basic",
    "tags": ["LangChain", "Benefits", "ModelAgnostic", "LLM", "Flexibility"],
    "id": "uuid-v4-placeholder-17"
  },
  {
    "front": "Name three types of components provided within LangChain's ecosystem for building LLM applications.",
    "back": "Any three of: Document Loaders, Text Splitters, Embedding Models, Vector Stores. (Others include: LLM wrappers, Chains, Agents, Memory tools)",
    "type": "basic",
    "tags": ["LangChain", "Ecosystem", "Components", "DevelopmentTools"],
    "mnemonic": "LangChain's ecosystem helps **D**evelopers **T**ackle **E**normous **V**olumes (of data/tasks) -> **D**ocument Loaders, **T**ext Splitters, **E**mbedding Models, **V**ector Stores.",
    "id": "uuid-v4-placeholder-18"
  },
  {
    "front": "LangChain includes mechanisms for managing {{c1::conversational memory}}, crucial for chatbots to recall previous interactions.",
    "back": "conversational memory",
    "type": "cloze",
    "tags": ["LangChain", "Features", "ConversationalMemory", "Chatbots", "StateHandling"],
    "examples": "If a user discusses 'linear regression' then asks about 'interview questions on _this_ algorithm,' memory helps link 'this' to linear regression.",
    "cloze_back_extra": "LangChain includes mechanisms for managing conversational memory, which is crucial for chatbots to remember previous parts of a conversation.",
    "id": "uuid-v4-placeholder-19"
  },
  {
    "front": "What is the main function of \"Chains\" in the LangChain framework?",
    "back": "To sequence calls to LLMs or other utilities, enabling the output of one step to serve as the input for the subsequent step, thereby constructing complex application workflows.",
    "type": "basic",
    "tags": ["LangChain", "Chains", "CoreConcept", "WorkflowAutomation"],
    "id": "uuid-v4-placeholder-30"
  }
]
